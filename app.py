import re

import streamlit as st
from pathlib import Path
from typing import List, Optional

import altair as alt
import pandas as pd

from analyzer.storage import (
    load_rules,
    save_rules,
    load_source_index,
    save_source_index,
    required_sources_present,
)
from analyzer.rules import RuleSet
from analyzer.engine import analyze
from analyzer.report import banner_lines, one_line, ms_to_hms
from analyzer.diagnostics import generate_diagnostic_report
from analyzer.learn import add_feedback
from analyzer.code_indexer import build_source_index
from analyzer.trace import collect_trace_datasets
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì•„ë˜ ì½”ë“œëŠ” ìƒˆ ë¸Œëœì¹˜(codex)ì—ì„œ ì¶”ê°€í•œ ë¶€ë¶„
from analyzer.viz import configure_altair

configure_altair()
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="OHT ë¡œê·¸ ë¶„ì„ê¸° (ë¡œê·¸ + ì½”ë“œ ì°¸ì¡°)", layout="wide")

st.markdown("## âœ… OHT ë¡œê·¸ ë¶„ì„ê¸° â€” ì¦ê±°-ìš°ì„  / ë³´ìˆ˜ì  ê²°ë¡  / í”¼ë“œë°± í•™ìŠµ / **ì½”ë“œ ZIP ìë™ì°¸ì¡°**")
st.caption("ì¶•: 0=Driving-Rear, 1=Driving-Front, 2=Hoist, 3=Slide | 1ms í†µì‹  | amulation/crc15_ccitt ì œì™¸")

current_idx = load_source_index()
vehicle_count = len(current_idx.get("vehicle", {}).get("map_num_to_name", {}))
motion_count = len(current_idx.get("motion", {}).get("map_num_to_name", {}))
idx_source = current_idx.get("meta", {}).get("source")

if vehicle_count and motion_count:
    if idx_source == "default_system":
        st.caption(
            f"í˜„ì¬ ê¸°ë³¸ ì‹œìŠ¤í…œ(motion_control + vehicle_control) ì½”ë“œ ë§¤í•‘: vehicle {vehicle_count}ê±´ + motion {motion_count}ê±´ì„ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤."
        )
    else:
        st.caption(
            f"í˜„ì¬ ì €ì¥ëœ ì½”ë“œ ë§¤í•‘ ì ìš© ì¤‘ â€” vehicle {vehicle_count}ê±´, motion {motion_count}ê±´."
        )
else:
    st.caption("í˜„ì¬ ì½”ë“œ ë§¤í•‘ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

with st.sidebar:
    st.markdown("### ì„¤ì • / ë£°ì…‹")
    rules_obj = load_rules()
    st.text(f"RuleSet: {rules_obj.get('version','v?')}")
    st.write("ì „ì¡° ìœˆë„ìš°(ì´ˆ):", rules_obj["time_window_sec"])
    if st.button("ë£°ì…‹ ì´ˆê¸°í™”(ê¸°ë³¸ê°’)"):
        save_rules(load_rules())
        st.success("ë£°ì…‹ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹")

    glossary = rules_obj.get("terminology") or rules_obj.get("glossary")
    if glossary:
        with st.expander("ì£¼ìš” ìš©ì–´ ì •ë¦¬"):
            for term, desc in glossary.items():
                st.markdown(f"**{term}**")
                st.caption(desc)

st.markdown("### 0) ì½”ë“œ ZIP ì—…ë¡œë“œ â€” vehicle_control.zip + motion_control.zip (í•„ìˆ˜)")
zip_col_vehicle, zip_col_motion = st.columns(2)
with zip_col_vehicle:
    vehicle_zip = st.file_uploader(
        "vehicle_control.zip (í•„ìˆ˜)", type=["zip"], accept_multiple_files=False, key="vehicle_zip"
    )
with zip_col_motion:
    motion_zip = st.file_uploader(
        "motion_control.zip (í•„ìˆ˜)", type=["zip"], accept_multiple_files=False, key="motion_zip"
    )

col_idx1, col_idx2 = st.columns([1, 3])
with col_idx1:
    if st.button("ì½”ë“œ ì¸ë±ì‹± â–¶ (vehicle + motion ë™ì‹œ)"):
        if not vehicle_zip or not motion_zip:
            st.error("vehicle_control.zipê³¼ motion_control.zipì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            try:
                try:
                    vehicle_zip.seek(0)
                    motion_zip.seek(0)
                except Exception:
                    pass
                vehicle_bytes = vehicle_zip.read()
                motion_bytes = motion_zip.read()
                with st.spinner("ì½”ë“œ ì¸ë±ì‹± ì¤‘..."):
                    idx = build_source_index(
                        vehicle_zip_bytes=vehicle_bytes,
                        motion_zip_bytes=motion_bytes,
                    )
                    save_source_index(idx)
                v_count = len(idx["vehicle"]["map_num_to_name"])
                m_count = len(idx["motion"]["map_num_to_name"])
                st.success(f"ì¸ë±ì‹± ì™„ë£Œ! vehicle {v_count}ê±´ + motion {m_count}ê±´")
            except Exception as exc:
                st.exception(exc)
with col_idx2:
    if st.button("í˜„ì¬ ì½”ë“œ ë§¤í•‘ ìš”ì•½ ë³´ê¸°"):
        idx = load_source_index()
        vehicle_preview = dict(list(idx.get("vehicle", {}).get("map_num_to_name", {}).items())[:20])
        motion_preview = dict(list(idx.get("motion", {}).get("map_num_to_name", {}).items())[:20])
        st.json(
            {
                "meta": idx.get("meta", {}),
                "vehicle": {"map_num_to_name": vehicle_preview},
                "motion": {"map_num_to_name": motion_preview},
            }
        )

if not required_sources_present():
    st.warning("vehicle_control.zipê³¼ motion_control.zipì„ ëª¨ë‘ ì¸ë±ì‹±í•´ì•¼ ë¡œê·¸ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

st.markdown("### 1) ë¡œê·¸ë°ì´í„° ì—…ë¡œë“œ")
uploads = st.file_uploader("ZIP ë˜ëŠ” LOG íŒŒì¼ ì—¬ëŸ¬ ê°œ ì„ íƒ", type=["zip","log","txt"], accept_multiple_files=True)
case_name = st.text_input("ì¼€ì´ìŠ¤ ì´ë¦„(ë¦¬í¬íŠ¸ í‘œê¸°ìš©)", value="CASE_001")

uploaded_paths: List[Path] = []
if uploads:
    tmpdir = Path("./_work"); tmpdir.mkdir(exist_ok=True)
    for f in uploads:
        p = tmpdir / f.name
        p.write_bytes(f.getbuffer())
        uploaded_paths.append(p)
    st.success(f"{len(uploaded_paths)}ê°œ ë¡œê·¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ")


def parse_error_code_input(raw: str) -> List[str]:
    if not raw:
        return []
    tokens = [tok.strip() for tok in re.split(r"[,\s]+", raw) if tok.strip()]
    codes: List[str] = []
    for token in tokens:
        if token.upper().startswith("E"):
            token = token[1:]
        token = token.strip()
        if token:
            codes.append(token)
    return codes


error_code_raw = st.text_input(
    "ë¶„ì„í•  ì—ëŸ¬ ì½”ë“œ (ì„ íƒ ì…ë ¥, ì‰¼í‘œ/ê³µë°± êµ¬ë¶„)",
    value="",
    placeholder="ì˜ˆ: 101 ë˜ëŠ” 101, 205",
)
selected_error_codes = parse_error_code_input(error_code_raw)
target_code_set = set(selected_error_codes) if selected_error_codes else None
if selected_error_codes:
    st.caption(
        "ì…ë ¥ëœ ì—ëŸ¬ ì½”ë“œë§Œ ìš°ì„  ë¶„ì„í•©ë‹ˆë‹¤: "
        + ", ".join(f"E{code}" for code in selected_error_codes)
    )

st.markdown("### 2) ë¡œê·¸ ë¶„ì„")
colA, colB = st.columns([1,3])
with colA:
    if st.button("ë¡œê·¸ ë¶„ì„ ì‹œì‘ â–¶"):
        st.session_state["analyze_now"] = True
with colB:
    st.info("ë¶„ì„ì€ **ì¦ê±°-ìš°ì„ **ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ê·¼ê±° ë¶€ì¡± ì‹œ **ë¯¸í™•ì •**ìœ¼ë¡œ ë³´ë¥˜í•©ë‹ˆë‹¤.")

if st.session_state.get("analyze_now") and uploaded_paths:
    with st.spinner("ë¶„ì„ ì¤‘..."):
        rs = RuleSet(load_rules(), code_index=load_source_index())
        result = analyze(uploaded_paths, rs, target_codes=target_code_set)
    st.success("ë¶„ì„ ì™„ë£Œ!")

    st.markdown("#### âœ” ê²€ì¦ ë°°ë„ˆ(ìš”ì•½)")
    st.code(banner_lines(result["banner"], rs.error_map), language="markdown")

    diagnostics = generate_diagnostic_report(result, rs)
    if diagnostics:
        st.markdown("#### ğŸ§  ìë™ ì§„ë‹¨ ìš”ì•½")
        for diag in diagnostics:
            title = f"E{diag['code']}"
            if diag.get("name"):
                title += f" ({diag['name']})"
            st.markdown(f"**{title}**")
            if diag.get("scenario"):
                st.write(diag["scenario"])
            st.write(diag["summary"])
            st.write(f"ì¶”ì • ì›ì¸: {diag['root_cause']}")
            st.write("ê¶Œì¥ ì¡°ì¹˜:")
            for act in diag["actions"]:
                st.markdown(f"- {act}")
            if diag["precursors"]:
                st.caption("ì „ì¡° ì´ë²¤íŠ¸")
                for p in diag["precursors"]:
                    st.code(p, language="text")
            else:
                st.caption("ì „ì¡° ì´ë²¤íŠ¸: ë°œê²¬ë˜ì§€ ì•ŠìŒ")
            if diag["drive"]:
                st.caption("ì£¼í–‰ ì¦ê±°")
                for d in diag["drive"]:
                    st.code(d, language="text")
            if diag["code_snippets"] or diag["log_samples"]:
                with st.expander("ê·¼ê±° ë³´ê¸°"):
                    if diag["log_samples"]:
                        st.write("ë¡œê·¸ ì•µì»¤ ìƒ˜í”Œ")
                        for sample in diag["log_samples"]:
                            st.code(sample, language="text")
                    if diag["code_snippets"]:
                        st.write("ì†ŒìŠ¤ ì½”ë“œ ê·¼ê±°")
                        for snippet in diag["code_snippets"]:
                            st.code(snippet, language="text")

    st.markdown("#### ğŸ” ì½”ë“œë³„ íƒ€ì„ë¼ì¸ & ì „ì¡°")
    for b in result["banner"]:
        code = str(b["code"]); name = rs.error_map.get(code, "")
        st.markdown(f"**E{code} {f'({name})' if name else ''}** â€” {ms_to_hms(b['first'])} ~ {ms_to_hms(b['last'])}, count={b['count']}")
        precs = [p for p in result["precursors"] if str(p["code"])==code]
        if precs:
            st.write(f"ì „ì¡° ì´ë²¤íŠ¸ {len(precs)}ê±´ (ì•µì»¤ ìµœì´ˆ ëŒ€ë¹„ Î”t ms):")
            for p in precs[:10]:
                st.code(one_line(p), language="text")
        else:
            st.write("ì „ì¡° ì´ë²¤íŠ¸: ì—†ìŒ")
        drives = [d for d in result["drive_samples"] if str(d["code"])==code]
        if drives:
            with st.expander("ì£¼í–‰ íŒíŠ¸ ì›ë¬¸ ë³´ê¸°"):
                for d in drives[:10]:
                    st.code(one_line(d), language="text")
        else:
            st.caption("ì£¼í–‰ íŒíŠ¸: ë¯¸í™•ì •(ì¦ê±° ë¶€ì¡±)")

    trace_datasets = collect_trace_datasets(uploaded_paths, rs, result)
    if trace_datasets:
        st.markdown("#### ğŸ“ˆ íŠ¸ë ˆì´ìŠ¤ ë¡œê·¸ ìƒì„¸ ë¶„ì„")
        st.caption("ì‹¤ì œ/ëª…ë ¹ ê¶¤ì ê³¼ í† í¬ë¥¼ ë¹„êµí•˜ê³  ì£¼ìš” ì´ë²¤íŠ¸ ì‹œì ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        for trace in trace_datasets:
            df = trace.frame
            header = f"{trace.file}"
            if trace.axis:
                header += f" Â· ì¶•: {trace.axis}"
            st.markdown(f"**{header}**")

            origin = df["time_ms"].iloc[0]
            error_df = pd.DataFrame({
                "time_offset_sec": [(t - origin) / 1000.0 for t in trace.error_times],
                "label": ["ì—ëŸ¬ ë°œìƒ"] * len(trace.error_times),
            }) if trace.error_times else pd.DataFrame(columns=["time_offset_sec", "label"])
            command_df = pd.DataFrame({
                "time_offset_sec": [(t - origin) / 1000.0 for t in trace.command_times],
                "label": ["ëª…ë ¹ ì‹œì "] * len(trace.command_times),
            }) if trace.command_times else pd.DataFrame(columns=["time_offset_sec", "label"])

            def _marker_layer(data: pd.DataFrame, color: str, dash: Optional[List[int]] = None):
                if data.empty:
                    return None
                mark = alt.Chart(data).mark_rule(color=color, strokeDash=dash)
                return mark.encode(
                    x=alt.X("time_offset_sec:Q", title="ì‹œê°„ (s)"),
                    tooltip=[alt.Tooltip("label:N", title="ì´ë²¤íŠ¸"), alt.Tooltip("time_offset_sec:Q", title="Î”t(s)")],
                )

            layers = []

            if {"actual_position", "command_position"}.intersection(df.columns):
                pos_cols = {}
                if "actual_position" in df.columns:
                    pos_cols["actual_position"] = "ì‹¤ì œ ìœ„ì¹˜"
                if "command_position" in df.columns:
                    pos_cols["command_position"] = "ëª…ë ¹ ìœ„ì¹˜"
                pos_df = df[["time_offset_sec", *pos_cols.keys()]].rename(columns=pos_cols)
                pos_melt = pos_df.melt("time_offset_sec", var_name="í•­ëª©", value_name="ê°’")
                pos_chart = alt.Chart(pos_melt).mark_line().encode(
                    x=alt.X("time_offset_sec:Q", title="ì‹œê°„ (s)"),
                    y=alt.Y("ê°’:Q", title="ìœ„ì¹˜"),
                    color=alt.Color("í•­ëª©:N", title=""),
                    tooltip=["í•­ëª©:N", alt.Tooltip("time_offset_sec:Q", title="Î”t(s)"), alt.Tooltip("ê°’:Q", title="ìœ„ì¹˜")],
                )
                layers.append((pos_chart, "ìœ„ì¹˜"))

            if {"actual_velocity", "command_velocity"}.intersection(df.columns):
                vel_cols = {}
                if "actual_velocity" in df.columns:
                    vel_cols["actual_velocity"] = "ì‹¤ì œ ì†ë„"
                if "command_velocity" in df.columns:
                    vel_cols["command_velocity"] = "ëª…ë ¹ ì†ë„"
                vel_df = df[["time_offset_sec", *vel_cols.keys()]].rename(columns=vel_cols)
                vel_melt = vel_df.melt("time_offset_sec", var_name="í•­ëª©", value_name="ê°’")
                vel_chart = alt.Chart(vel_melt).mark_line().encode(
                    x=alt.X("time_offset_sec:Q", title="ì‹œê°„ (s)"),
                    y=alt.Y("ê°’:Q", title="ì†ë„"),
                    color=alt.Color("í•­ëª©:N", title=""),
                    tooltip=["í•­ëª©:N", alt.Tooltip("time_offset_sec:Q", title="Î”t(s)"), alt.Tooltip("ê°’:Q", title="ì†ë„")],
                )
                layers.append((vel_chart, "ì†ë„"))

            if "torque_percent" in df.columns:
                tq_chart = alt.Chart(df).mark_line(color="#9467bd").encode(
                    x=alt.X("time_offset_sec:Q", title="ì‹œê°„ (s)"),
                    y=alt.Y("torque_percent:Q", title="í† í¬(%)"),
                    tooltip=[alt.Tooltip("time_offset_sec:Q", title="Î”t(s)"), alt.Tooltip("torque_percent:Q", title="í† í¬(%)")],
                )
                layers.append((tq_chart, "í† í¬"))

            marker_layers = [
                layer
                for layer in (
                    _marker_layer(error_df, "#d62728"),
                    _marker_layer(command_df, "#1f77b4", dash=[4, 4]),
                )
                if layer is not None
            ]

            for chart, title in layers:
                combined = alt.layer(chart, *marker_layers) if marker_layers else chart
                st.altair_chart(combined.properties(height=240), use_container_width=True)
                st.caption(f"Â· {title} ì¶”ì„¸")

    st.markdown("---")
    st.markdown("### ì„¹ì…˜ë³„ ë¦¬í¬íŠ¸ (ì‘ì—…ììš©)")
    ordered = [
        "ë§ˆìŠ¤í„°ë¡œê·¸","íŠ¸ë ˆì´ìŠ¤_C","íŠ¸ë ˆì´ìŠ¤_M","AMC_Recv","MCC","User","AMC_Send_Periodic","AMC_Send",
        "Assistant","AutoRecovery","BCR","BCR_RawData","CarrierID","CID-LOG","CmdManager","CPUandMemInfo",
        "DETECT","DiagManager","DrivingCtrl","EQPIOError","Execute","ExecuteJobThread","FM","HIDRawData",
        "IOTComm","IOTHUB","ManualControl","Monitor","MonitoringDetail","OHTDETECTWarnning","Passpermit",
        "PathSearch","QRTest","Shutter","SOS_Rcv_RawData","ThreadCycle","TaskControl","UBGPatternCom",
        "UDPCommunication","WirelessNet"
    ]
    sec = result["section"]
    for cat in ordered:
        if cat in sec:
            s = sec[cat]
            st.markdown(f"**- {cat} ë¶„ì„ê²°ê³¼**")
            st.write("íŒŒì¼:", ', '.join(sorted(set(s['files']))))
            st.write("ì‹œê°„:", ms_to_hms(s["first"]), "~", ms_to_hms(s["last"]))
            if s["samples"]:
                with st.expander("ê·¼ê±° ì›ë¬¸ ìƒ˜í”Œ"):
                    for rec in s["samples"][:8]:
                        st.code(one_line(rec), language="text")
            st.markdown('---')

st.markdown("### 3) í”¼ë“œë°± / ì¬í•™ìŠµ")
with st.form("feedback_form"):
    st.write("**ì¶”ê°€ ì „ì¡° íŒ¨í„´**ì´ë‚˜ **í˜¼ë™ì–´(ì—ëŸ¬ ì•„ë‹˜)**ë¥¼ ì…ë ¥í•˜ë©´ ì¦‰ì‹œ ë£°ì…‹ì— ë°˜ì˜ë©ë‹ˆë‹¤. (ì •ê·œì‹ ê°€ëŠ¥)")
    fb_comment = st.text_area("í”¼ë“œë°± ë©”ëª¨", "")
    new_precursors = st.text_area("ì¶”ê°€ ì „ì¡° íŒ¨í„´ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)", "")
    new_confusions = st.text_area("ì¶”ê°€ í˜¼ë™ì–´(ì—ëŸ¬ ì•„ë‹˜) íŒ¨í„´ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)", "")
    submitted = st.form_submit_button("í”¼ë“œë°± ì €ì¥ & ë£° ì—…ë°ì´íŠ¸")
    if submitted:
        pc = [s.strip() for s in new_precursors.splitlines() if s.strip()]
        cf = [s.strip() for s in new_confusions.splitlines() if s.strip()]
        rules_after = add_feedback(case_name, fb_comment, pc, cf)
        st.success("í”¼ë“œë°± ì €ì¥ & ë£° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        st.json({"added_precursors": pc, "added_confusions": cf, "rules_version": rules_after.get("version","v1.0")})

if st.button("í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ì¬ë¶„ì„ â–¶"):
    if uploads:
        with st.spinner("ì¬ë¶„ì„ ì¤‘..."):
            rs = RuleSet(load_rules(), code_index=load_source_index())
            result = analyze([Path("./_work")], rs, target_codes=target_code_set)
        st.success("ì¬ë¶„ì„ ì™„ë£Œ")
        st.code(banner_lines(result["banner"], rs.error_map), language="markdown")
    else:
        st.warning("ë¨¼ì € ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
